{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greater-wright",
   "metadata": {},
   "source": [
    "# Simple CNN text classification\n",
    "Inspired by https://towardsdatascience.com/text-classification-with-cnns-in-pytorch-1113df31e79f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-cliff",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "searching-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetMapper(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-parallel",
   "metadata": {},
   "source": [
    "## Build, train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affiliated-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.ModuleList):\n",
    "    def __init__(self, params):\n",
    "        super(TextClassifier, self).__init__()\n",
    "  \n",
    "        # Parameters regarding text preprocessing\n",
    "        self.seq_len = params.seq_len\n",
    "        self.num_words = params.num_words\n",
    "        self.embedding_size = params.embedding_size\n",
    "        \n",
    "        # Dropout definition\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # CNN parameters definition\n",
    "        # Kernel sizes\n",
    "        self.kernel_1 = 2\n",
    "        self.kernel_2 = 3\n",
    "        self.kernel_3 = 4\n",
    "        self.kernel_4 = 5\n",
    "        \n",
    "        # Output size for each convolution\n",
    "        self.out_size = params.out_size\n",
    "        # Number of strides for each convolution\n",
    "        self.stride = params.stride\n",
    "        \n",
    "        # Embedding layer definition\n",
    "        self.embedding = nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0)\n",
    "        \n",
    "        # Convolution layers definition\n",
    "        self.conv_1 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_1, self.stride)\n",
    "        self.conv_2 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_2, self.stride)\n",
    "        self.conv_3 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_3, self.stride)\n",
    "        self.conv_4 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_4, self.stride)\n",
    "        \n",
    "        # Max pooling layers definition\n",
    "        self.pool_1 = nn.MaxPool1d(self.kernel_1, self.stride)\n",
    "        self.pool_2 = nn.MaxPool1d(self.kernel_2, self.stride)\n",
    "        self.pool_3 = nn.MaxPool1d(self.kernel_3, self.stride)\n",
    "        self.pool_4 = nn.MaxPool1d(self.kernel_4, self.stride)\n",
    "        \n",
    "        # Fully connected layer definition\n",
    "        self.fc = nn.Linear(self.in_features_fc(), 1)\n",
    "\n",
    "    def in_features_fc(self):\n",
    "        '''Calculates the number of output features after Convolution + Max pooling\n",
    "\n",
    "        Convolved_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "        Pooled_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "\n",
    "        source: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        '''\n",
    "        # Calculate size of convolved/pooled features for convolution_1/max_pooling_1 features\n",
    "        out_conv_1 = ((self.embedding_size - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_1 = math.floor(out_conv_1)\n",
    "        out_pool_1 = ((out_conv_1 - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_1 = math.floor(out_pool_1)\n",
    "\n",
    "        # Calculate size of convolved/pooled features for convolution_2/max_pooling_2 features\n",
    "        out_conv_2 = ((self.embedding_size - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_2 = math.floor(out_conv_2)\n",
    "        out_pool_2 = ((out_conv_2 - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_2 = math.floor(out_pool_2)\n",
    "\n",
    "        # Calculate size of convolved/pooled features for convolution_3/max_pooling_3 features\n",
    "        out_conv_3 = ((self.embedding_size - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_3 = math.floor(out_conv_3)\n",
    "        out_pool_3 = ((out_conv_3 - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_3 = math.floor(out_pool_3)\n",
    "\n",
    "        # Calculate size of convolved/pooled features for convolution_4/max_pooling_4 features\n",
    "        out_conv_4 = ((self.embedding_size - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_4 = math.floor(out_conv_4)\n",
    "        out_pool_4 = ((out_conv_4 - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_4 = math.floor(out_pool_4)\n",
    "\n",
    "        # Returns \"flattened\" vector (input for fully connected layer)\n",
    "        return (out_pool_1 + out_pool_2 + out_pool_3 + out_pool_4) * self.out_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Sequence of tokes is filterd through an embedding layer\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Convolution layer 1 is applied\n",
    "        x1 = self.conv_1(x)\n",
    "        x1 = torch.relu(x1)\n",
    "        x1 = self.pool_1(x1)\n",
    "        \n",
    "        # Convolution layer 2 is applied\n",
    "        x2 = self.conv_2(x)\n",
    "        x2 = torch.relu((x2))\n",
    "        x2 = self.pool_2(x2)\n",
    "        \n",
    "        # Convolution layer 3 is applied\n",
    "        x3 = self.conv_3(x)\n",
    "        x3 = torch.relu(x3)\n",
    "        x3 = self.pool_3(x3)\n",
    "        \n",
    "        # Convolution layer 4 is applied\n",
    "        x4 = self.conv_4(x)\n",
    "        x4 = torch.relu(x4)\n",
    "        x4 = self.pool_4(x4)\n",
    "        \n",
    "        # The output of each convolutional layer is concatenated into a unique vector\n",
    "        union = torch.cat((x1, x2, x3, x4), 2)\n",
    "        union = union.reshape(union.size(0), -1)\n",
    "    \n",
    "        # The \"flattened\" vector is passed through a fully connected layer\n",
    "        out = self.fc(union)\n",
    "        # Dropout is applied\t\t\n",
    "        out = self.dropout(out)\n",
    "        # Activation function is applied\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
